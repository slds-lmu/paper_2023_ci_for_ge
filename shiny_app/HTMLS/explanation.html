<div style='text-align:left;'><p>

This shiny-app is a visual exploration of a large-scale benchmark experiment that compared various methods for constructing confidence intervals for the generalization error.<br><br>

The general dimensions of the analysis are:<br>

<ul>
  <li> <b>Method</b>:
       The inference method (see tab TODO for an explanation of the abbreviations used on the website).
  <li> <b>DGPs</b>:
       The data-generating process (see tab Datasets).
  <li> <b>Inducers</b>:
       The inducing algorithm, which includes a linear model / logistic regression, a (logistic) ridge regression, a decision tree and a random forest.
  <li> <b>Dataset Size</b>:
       The size of the datasets (100, 500, 1000, 5000 and 10000).<br> Note that expensive methods are not applied to all dataset sizes.
  <li> <b>Loss Function</b>:
       The loss function used to evaluate the performance of the trained models.<br>
       For <i>regression</i>, the squared, absolte, percentual squared, and standardized squared error are available.<br>
       For <i>classification</i>, the zero-one, binary brier and log-loss can be selected.
  <li> <b>Target Quantity</b>:
       We evaluate the coverage of the confidence intervals with respect to three target quantity, namely the Risk, the Expected Risk and the proxy quantity (if applicable).
</ul>

</p><p>&nbsp;</p><hr><p>&nbsp;</p>
</div>
